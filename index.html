<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mi escena de realidad aumentada</title>
  <script src="https://aframe.io/releases/1.6.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar-nft.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-extras@7.5.0/dist/aframe-extras.min.js"></script>
</head>

<body style="margin: 0; overflow: hidden;" ontouchstart="playSound()">
  <a-scene embedded arjs="sourceType: webcam; detectionMode: mono_and_matrix; matrixCodeType: 3x3;">
    <a-marker type="pattern" url="assets/pattern-Group.patt">
      <a-entity gltf-model="assets/esapAnimation.glb" scale="0.5 0.5 0.5" position="0 0 0" rotation="-110 0 0"
        animation-mixer="clip: *;loop: repeat;"
        sound="src: url(assets/esapAudio.mp3); on: click;">
      </a-entity>
    </a-marker>
    <a-entity camera></a-entity>
    <!-- <a-sound src="src: url(assets/esapAudio.mp3)" autoplay="true"></a-sound> -->
  </a-scene>







  <script>
    function playSound() {
      var soundEntity = document.querySelector('[sound]');
      if (soundEntity && !soundEntity.components.sound.isPlaying) {
        soundEntity.components.sound.playSound();
      }
    }
    
    // También puedes escuchar el evento de interacción en el marcador
    document.querySelector('a-marker').addEventListener('click', function () {
      playSound();
    });

    // Detectar el evento de toque en móviles
    document.querySelector('a-marker').addEventListener('touchstart', function () {
      playSound();
    });
  </script>
</body>



</html>